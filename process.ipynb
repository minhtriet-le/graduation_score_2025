{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56e63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# from unidecode import unidecode\n",
    "\n",
    "# def export_to_parquet(folder_name, output_filename=\"combined_data.parquet\"):\n",
    "#     \"\"\"\n",
    "#     Read all Excel files in the given folder (including all sheets),\n",
    "#     normalize column names, concatenate into a single DataFrame,\n",
    "#     and write the result to a Parquet file.\n",
    "\n",
    "#     Args:\n",
    "#         folder_name (str): Path to folder containing .xlsx files.\n",
    "#         output_filename (str): Output Parquet filename.\n",
    "#     \"\"\"\n",
    "#     data_dir = Path(folder_name)\n",
    "#     all_dfs = []\n",
    "\n",
    "#     # 1. Collect all data from each Excel file and each sheet\n",
    "#     for file_path in data_dir.glob(\"*.xlsx\"):\n",
    "#         print(f\"Reading: {file_path.name}\")\n",
    "#         # Read all sheets into a dict: {sheet_name: DataFrame}\n",
    "#         excel_data = pd.read_excel(file_path, sheet_name=None)\n",
    "        \n",
    "#         for sheet_name, df in excel_data.items():\n",
    "#             # Add metadata columns to keep track of origin\n",
    "#             df['origin_file'] = file_path.name\n",
    "#             df['origin_sheet'] = str(sheet_name)\n",
    "            \n",
    "#             # Ensure all column names are strings (Parquet requires string column names)\n",
    "#             df.columns = df.columns.astype(str)\n",
    "            \n",
    "#             all_dfs.append(df)\n",
    "\n",
    "#     if not all_dfs:\n",
    "#         print(\"No data found to export.\")\n",
    "#         return\n",
    "\n",
    "#     # 2. Concatenate all DataFrames into a single DataFrame\n",
    "#     final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "#     # Normalize column names: remove accents, make lowercase, replace spaces with underscores\n",
    "#     final_df.columns = [unidecode(col).lower().replace(' ', '_') for col in final_df.columns]\n",
    "\n",
    "#     final_df = final_df[final_df['sobaodanh'].notna()]\n",
    "#     final_df['sobaodanh'] = final_df['sobaodanh'].astype(int).astype(str).str.zfill(8)\n",
    "\n",
    "#     # Select and reorder the columns we care about. If some columns are missing, this will raise a KeyError.\n",
    "#     # (Keep this explicit selection to preserve a consistent schema across inputs.)\n",
    "#     final_df = final_df[['sobaodanh', 'toan', 'van', 'li', 'hoa', 'sinh', 'tin_hoc',\n",
    "#        'cong_nghe_cong_nghiep', 'cong_nghe_nong_nghiep', 'su', 'dia',\n",
    "#        'giao_duc_kinh_te_va_phap_luat', 'ngoai_ngu', 'giao_duc_cong_dan',\n",
    "#        'ma_mon_ngoai_ngu', 'origin_file', 'origin_sheet']]\n",
    "    \n",
    "#     # String columns\n",
    "#     string_cols = [\n",
    "#         'sobaodanh',\n",
    "#         'ma_mon_ngoai_ngu',\n",
    "#         'origin_file',\n",
    "#         'origin_sheet'\n",
    "#     ]\n",
    "\n",
    "#     for col in string_cols:\n",
    "#         if col in final_df.columns:\n",
    "#             final_df[col] = final_df[col].astype('string')\n",
    "\n",
    "#     # Score columns → float32 (memory efficient)\n",
    "#     score_cols = [\n",
    "#         'toan', 'van', 'li', 'hoa', 'sinh', 'tin_hoc',\n",
    "#         'cong_nghe_cong_nghiep', 'cong_nghe_nong_nghiep',\n",
    "#         'su', 'dia', 'giao_duc_kinh_te_va_phap_luat',\n",
    "#         'ngoai_ngu', 'giao_duc_cong_dan'\n",
    "#     ]\n",
    "\n",
    "#     for col in score_cols:\n",
    "#         if col in final_df.columns:\n",
    "#             final_df[col] = pd.to_numeric(final_df[col], errors='coerce').astype('float32')\n",
    "\n",
    "#     final_df = final_df.sort_values('sobaodanh').reset_index(drop=True)\n",
    "    \n",
    "#     # 3. Export to Parquet using pyarrow (fast and supports complex types)\n",
    "#     final_df.to_parquet(output_filename, engine='pyarrow', index=False)\n",
    "    \n",
    "#     print(\"-\" * 30)\n",
    "#     print(f\"Success: data exported to {output_filename}\")\n",
    "#     print(f\"Total rows: {len(final_df)}\")\n",
    "#     print(f\"Total columns: {len(final_df.columns)}\")\n",
    "\n",
    "# # Execute the export on the 'raw_data' folder\n",
    "# export_to_parquet(\"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b2b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1153226 entries, 0 to 1153225\n",
      "Data columns (total 17 columns):\n",
      " #   Column                         Non-Null Count    Dtype  \n",
      "---  ------                         --------------    -----  \n",
      " 0   sobaodanh                      1153226 non-null  string \n",
      " 1   toan                           1137417 non-null  float32\n",
      " 2   van                            1144098 non-null  float32\n",
      " 3   li                             351733 non-null   float32\n",
      " 4   hoa                            244283 non-null   float32\n",
      " 5   sinh                           71616 non-null    float32\n",
      " 6   tin_hoc                        7602 non-null     float32\n",
      " 7   cong_nghe_cong_nghiep          2290 non-null     float32\n",
      " 8   cong_nghe_nong_nghiep          22048 non-null    float32\n",
      " 9   su                             495165 non-null   float32\n",
      " 10  dia                            489581 non-null   float32\n",
      " 11  giao_duc_kinh_te_va_phap_luat  246401 non-null   float32\n",
      " 12  ngoai_ngu                      362975 non-null   float32\n",
      " 13  giao_duc_cong_dan              4099 non-null     float32\n",
      " 14  ma_mon_ngoai_ngu               362975 non-null   string \n",
      " 15  origin_file                    1153226 non-null  string \n",
      " 16  origin_sheet                   1153226 non-null  string \n",
      "dtypes: float32(13), string(4)\n",
      "memory usage: 92.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the combined Parquet file and display the first few rows\n",
    "df = pd.read_parquet('combined_data.parquet')\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f41c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Saved: toan.png\n",
      "--- Saved: van.png\n",
      "--- Saved: li.png\n",
      "--- Saved: hoa.png\n",
      "--- Saved: sinh.png\n",
      "--- Saved: tin_hoc.png\n",
      "--- Saved: cong_nghe_cong_nghiep.png\n",
      "--- Saved: cong_nghe_nong_nghiep.png\n",
      "--- Saved: su.png\n",
      "--- Saved: dia.png\n",
      "--- Saved: giao_duc_kinh_te_va_phap_luat.png\n",
      "--- Saved: giao_duc_cong_dan.png\n",
      "\n",
      "--- Exporting foreign language score charts (N1–N7) ---\n",
      "   [OK] Saved: ngoai_ngu_N1.png\n",
      "   [OK] Saved: ngoai_ngu_N2.png\n",
      "   [OK] Saved: ngoai_ngu_N3.png\n",
      "   [OK] Saved: ngoai_ngu_N4.png\n",
      "   [OK] Saved: ngoai_ngu_N5.png\n",
      "   [OK] Saved: ngoai_ngu_N6.png\n",
      "   [OK] Saved: ngoai_ngu_N7.png\n",
      "\n",
      "Done! All charts saved to folder: 'charts'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ==============================\n",
    "# Global Style\n",
    "# ==============================\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "# Assume df is already loaded in a previous cell\n",
    "# df = pd.read_parquet(\"combined_data.parquet\")\n",
    "\n",
    "bins = np.arange(0, 10.5, 0.5)\n",
    "\n",
    "# Human-readable Vietnamese display names for each subject column\n",
    "SUBJECT_LABELS = {\n",
    "    \"toan\":                        \"Toán\",\n",
    "    \"van\":                         \"Ngữ văn\",\n",
    "    \"li\":                          \"Vật lí\",\n",
    "    \"hoa\":                         \"Hóa học\",\n",
    "    \"sinh\":                        \"Sinh học\",\n",
    "    \"tin_hoc\":                     \"Tin học\",\n",
    "    \"cong_nghe_cong_nghiep\":       \"Công nghệ Công nghiệp\",\n",
    "    \"cong_nghe_nong_nghiep\":       \"Công nghệ Nông nghiệp\",\n",
    "    \"su\":                          \"Lịch sử\",\n",
    "    \"dia\":                         \"Địa lí\",\n",
    "    \"giao_duc_kinh_te_va_phap_luat\": \"Giáo dục Kinh tế và Pháp luật\",\n",
    "    \"ngoai_ngu\":                   \"Ngoại ngữ\",\n",
    "    \"giao_duc_cong_dan\":           \"Giáo dục Công dân\",\n",
    "}\n",
    "\n",
    "# Vietnamese labels for each foreign-language code\n",
    "FOREIGN_LANG_LABELS = {\n",
    "    \"N1\": \"Tiếng Anh\",\n",
    "    \"N2\": \"Tiếng Nga\",\n",
    "    \"N3\": \"Tiếng Pháp\",\n",
    "    \"N4\": \"Tiếng Trung\",\n",
    "    \"N5\": \"Tiếng Đức\",\n",
    "    \"N6\": \"Tiếng Nhật\",\n",
    "    \"N7\": \"Tiếng Hàn\",\n",
    "}\n",
    "\n",
    "def plot_and_save(data, title, filename):\n",
    "    \"\"\"Plot a histogram of score data, annotate it with summary stats, and save to disk.\"\"\"\n",
    "    n = len(data)\n",
    "    mean = data.mean()\n",
    "    median = data.median()\n",
    "    std = data.std()\n",
    "    count_10 = (data == 10).sum()\n",
    "    count_0 = (data == 0).sum()\n",
    "\n",
    "    # Create figure and axes explicitly\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "    sns.histplot(\n",
    "        data,\n",
    "        bins=bins,\n",
    "        binrange=(0, 10),\n",
    "        kde=False,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Điểm số\")\n",
    "    ax.set_ylabel(\"Số lượng thí sinh\")\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_xticks(bins)\n",
    "\n",
    "    # Summary statistics box — labels kept in Vietnamese for the rendered chart\n",
    "    summary_text = (\n",
    "        f\"Số thí sinh: {n:,}\\n\"\n",
    "        f\"ĐTB: {mean:.2f}\\n\"\n",
    "        f\"Trung vị: {median:.2f}\\n\"\n",
    "        f\"Độ lệch chuẩn: {std:.2f}\\n\"\n",
    "        f\"Số điểm 10: {count_10:,}\\n\"\n",
    "        f\"Số điểm 0: {count_0:,}\"\n",
    "    )\n",
    "\n",
    "    # Place the text box inside the chart area; adjust coordinates if needed\n",
    "    plt.gcf().text(\n",
    "        0.15, 0.7,\n",
    "        summary_text,\n",
    "        fontsize=12,\n",
    "        bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray')\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # KEY: save before show to capture the full layout including the text box\n",
    "    plt.savefig(filename, dpi=120, bbox_inches='tight')\n",
    "\n",
    "    # Comment out plt.show() when processing many charts to avoid blocking\n",
    "    # plt.show()\n",
    "\n",
    "    plt.close(fig)  # Release memory after saving\n",
    "\n",
    "# ==============================\n",
    "# Loop over all numeric score columns (except ngoai_ngu, handled separately)\n",
    "# ==============================\n",
    "output_dir = \"charts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "score_columns = df.select_dtypes(include=[\"float32\", \"float64\"]).columns\n",
    "score_columns = score_columns.drop(\"ngoai_ngu\", errors=\"ignore\")\n",
    "\n",
    "for col in score_columns:\n",
    "    data = df[col].dropna()\n",
    "    if not data.empty:\n",
    "        file_path = os.path.join(output_dir, f\"{col}.png\")\n",
    "        # Use the Vietnamese display name for the chart title if available\n",
    "        label = SUBJECT_LABELS.get(col, col)\n",
    "        plot_and_save(data, f\"Phân bố điểm - {label}\", file_path)\n",
    "        print(f\"--- Saved: {col}.png\")\n",
    "\n",
    "# ==============================\n",
    "# Handle Foreign Language subject (split by language code N1–N7)\n",
    "# ==============================\n",
    "if \"ngoai_ngu\" in df.columns and \"ma_mon_ngoai_ngu\" in df.columns:\n",
    "    print(\"\\n--- Exporting foreign language score charts (N1–N7) ---\")\n",
    "\n",
    "    # Keep only rows where both the score and language code are present\n",
    "    langs = df[[\"ngoai_ngu\", \"ma_mon_ngoai_ngu\"]].dropna(subset=[\"ngoai_ngu\", \"ma_mon_ngoai_ngu\"])\n",
    "\n",
    "    # Iterate over each language code (N1, N2, ..., N7)\n",
    "    for code, group in langs.groupby(\"ma_mon_ngoai_ngu\"):\n",
    "\n",
    "        # Build the output file path (e.g., ngoai_ngu_N1.png)\n",
    "        filename = f\"ngoai_ngu_{code}.png\"\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Use the Vietnamese language name for the chart title\n",
    "        lang_name = FOREIGN_LANG_LABELS.get(code, code)\n",
    "        chart_title = f\"Phân bố điểm Ngoại ngữ - {lang_name} ({code})\"\n",
    "\n",
    "        plot_and_save(group[\"ngoai_ngu\"], chart_title, file_path)\n",
    "        print(f\"   [OK] Saved: {filename}\")\n",
    "\n",
    "print(f\"\\nDone! All charts saved to folder: '{output_dir}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
